# ðŸŽ¯ AI Accreditation Dashboard â€“ Week 1

This project is part of the AI Accreditation study. The goal is to build a **Streamlit dashboard** that evaluates operators against ethical criteria using Gatekeepers, ARAS (Additive Ratio Assessment System), and tiering (Platinum/Gold/Silver/Bronze).

ðŸ‘‰ Live demo (Week-1): [https://ai-accreditation-week-1-deliverables.streamlit.app/](https://ai-accreditation-week-1-deliverables.streamlit.app/)

---

## ðŸ“‚ Project Structure
```
ai-accreditation/
â”œâ”€ streamlit_app.py        # Streamlit app entry point
â”œâ”€ requirements.txt        # Python dependencies
â”œâ”€ data/                   # Input data files
â”‚  â”œâ”€ criteria_catalog.csv
â”‚  â”œâ”€ delphi_round1_example.csv
â”‚  â”œâ”€ weights_from_delphi_example.csv
â”‚  â””â”€ operator_scores_dummy.csv
â””â”€ README.md
```

---

## ðŸš€ Running Locally
1. Clone the repo:
   ```bash
   git clone https://github.com/valetivivek/ai-accreditation.git
   cd ai-accreditation
   ```
2. Create a virtual environment and install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Launch the app:
   ```bash
   streamlit run streamlit_app.py
   ```
4. Open [http://localhost:8501](http://localhost:8501) in your browser.

---

## ðŸ“Š Week-1 Milestone
- âœ… Created project structure with `/data` subfolder.  
- âœ… Added CSV files and confirmed they load.  
- âœ… Built static dashboard pages:
  - **Overview** â€“ shows project goals.  
  - **Weights** â€“ displays Delphi expert inputs & (if provided) precomputed weights.  
  - **Scores** â€“ shows operator scores and criteria catalog.  
  - **Results** â€“ placeholder (to be filled in from Week-3 onward).  
  - **Export** â€“ allows downloading a snapshot CSV of current data.  